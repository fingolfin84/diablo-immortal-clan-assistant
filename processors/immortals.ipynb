{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_screenshots = Path.home() / \"Pictures/Screenshots/20220905\"\n",
    "path_out = Path(\"./out/members.csv\")\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:/Program Files/Tesseract-OCR/tesseract.exe\"\n",
    "\n",
    "clan_map = {\"Cowkings Desc\": \"Cowkings Descendants\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_base(items):\n",
    "    out = list()\n",
    "\n",
    "    items = filter(None, items.split(\"\\n\"))\n",
    "\n",
    "    for item in items:\n",
    "        out.append(item)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def parse_names(names):\n",
    "    out = list()\n",
    "\n",
    "    names_iter = iter(filter(None, names.split(\"\\n\")))\n",
    "\n",
    "    for name, level in zip(*[names_iter] * 2):\n",
    "        # remove errant dash and underscores due to profile frame\n",
    "        if name[:1] == \"-\" or name[:1] == \"_\":\n",
    "            name = name[1:]\n",
    "\n",
    "        # trim parens\n",
    "        level = level[9:-1]\n",
    "\n",
    "        out.append((name, int(level)))\n",
    "\n",
    "    return list(zip(*out))\n",
    "\n",
    "\n",
    "def parse_clans(clans):\n",
    "    out = list()\n",
    "\n",
    "    clans = filter(None, clans.split(\"\\n\"))\n",
    "\n",
    "    for clan in clans:\n",
    "        clan = clan_map.get(clan, clan)\n",
    "        out.append(clan)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def parse_roles(roles):\n",
    "    return parse_base(roles)\n",
    "\n",
    "\n",
    "def parse_contributions(contributions):\n",
    "    return [int(x) for x in parse_base(contributions)]\n",
    "\n",
    "\n",
    "def parse_member_data(img, parser, config=None):\n",
    "    member_data = parser(pytesseract.image_to_string(img, config=config))\n",
    "\n",
    "    def verify_data_len(data):\n",
    "        if (data_len := len(data)) != 5:\n",
    "            raise Exception(f\"Expected 5 members but found {data_len}: {data}.\")\n",
    "\n",
    "    # Support verifying length of member data containing tuples.\n",
    "    if any(isinstance(x, tuple) for x in member_data):\n",
    "        [verify_data_len(x) for x in member_data]\n",
    "    else:\n",
    "        verify_data_len(member_data)\n",
    "\n",
    "    return member_data\n",
    "\n",
    "\n",
    "def process_member_crop(img, y1, y2, x1, x2, parser, config=None):\n",
    "    img_crop = img[y1:y2, x1:x2]\n",
    "    img_tresh = cv2.threshold(\n",
    "        img_crop, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )[1]\n",
    "\n",
    "    try:\n",
    "        member_data = parse_member_data(img_tresh, parser, config)\n",
    "    except:\n",
    "        # Retry at 2x scale to handle crops with mostly single digit words.\n",
    "        (h, w) = img_crop.shape[:2]\n",
    "        img_crop = cv2.resize(img_crop, (w * 2, h * 2))\n",
    "        img_tresh = cv2.threshold(\n",
    "            img_crop, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )[1]\n",
    "        member_data = parse_member_data(img_tresh, parser, config)\n",
    "\n",
    "    return member_data\n",
    "\n",
    "\n",
    "def process_members(path):\n",
    "    # Load image\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Generate and process image crop for names and levels\n",
    "    names, levels = process_member_crop(img, 607, 1715, 1215, 1700, parse_names)\n",
    "\n",
    "    # Generate and process image crop for clans\n",
    "    clans = process_member_crop(\n",
    "        img,\n",
    "        607,\n",
    "        1715,\n",
    "        1700,\n",
    "        2250,\n",
    "        parse_clans,\n",
    "        config=r'--psm 6 -c tessedit_char_whitelist=\"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \"'\n",
    "    )\n",
    "\n",
    "    # Generate and process image crop for roles\n",
    "    roles = process_member_crop(img, 607, 1715, 2250, 2600, parse_roles)\n",
    "\n",
    "    # Generate and process image crop for contribution levels\n",
    "    contributions = process_member_crop(\n",
    "        img,\n",
    "        607,\n",
    "        1715,\n",
    "        2800,\n",
    "        3100,\n",
    "        parse_contributions,\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789\",\n",
    "    )\n",
    "\n",
    "    # Merge data.\n",
    "    data = [names, levels, clans, roles, contributions]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        list(zip(*data)), columns=[\"Name\", \"Level\", \"Clan\", \"Role\", \"Contribution\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_attrib(img, expected_count, config=None):\n",
    "    attrib = pytesseract.image_to_string(img, config=config)\n",
    "    attrib = parse_base(attrib)\n",
    "    if (attrib_len := len(attrib)) != expected_count:\n",
    "        # plt.imshow(img, cmap=\"gray\")\n",
    "        raise Exception(\n",
    "            f\"Expected {expected_count} attributes but found {attrib_len}: {attrib}.\"\n",
    "        )\n",
    "    return attrib\n",
    "\n",
    "\n",
    "def process_attrib_crop(path, y1, y2, x1, x2, expected_count, config=None):\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    img_crop = img[y1:y2, x1:x2]\n",
    "    img_thresh = cv2.threshold(\n",
    "        img_crop, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "    )[1]\n",
    "\n",
    "    try:\n",
    "        attrib = parse_attrib(img_thresh, expected_count, config)\n",
    "    except:\n",
    "        (h, w) = img_crop.shape[:2]\n",
    "        img_crop = cv2.resize(img_crop, (w * 2, h * 2))\n",
    "        img_thresh = cv2.threshold(\n",
    "            img_crop, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU\n",
    "        )[1]\n",
    "        attrib = parse_attrib(img_thresh, expected_count, config)\n",
    "\n",
    "    return attrib\n",
    "\n",
    "\n",
    "def process_member_attributes(paths):\n",
    "    attrib = dict()\n",
    "\n",
    "    # Process primary attributes\n",
    "    attrib_1_keys = [\n",
    "        \"Damage\",\n",
    "        \"Life\",\n",
    "        \"Strength\",\n",
    "        \"Intelligence\",\n",
    "        \"Fortitude\",\n",
    "        \"Vitality\",\n",
    "        \"Willpower\",\n",
    "    ]\n",
    "    attrib_1 = process_attrib_crop(\n",
    "        paths[0],\n",
    "        530,\n",
    "        1660,\n",
    "        3000,\n",
    "        3210,\n",
    "        len(attrib_1_keys),\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789\",\n",
    "    )\n",
    "    attrib_1 = [int(a) for a in attrib_1]\n",
    "    attrib |= dict(zip(attrib_1_keys, attrib_1))\n",
    "\n",
    "    # Process secondary attributes: Combat Rating ... Resistance\n",
    "    attrib_2_keys = [\n",
    "        \"CombatRating\",\n",
    "        \"Armor\",\n",
    "        \"ArmorPenetration\",\n",
    "        \"Potency\",\n",
    "        \"Resistance\",\n",
    "    ]\n",
    "    attrib_2 = process_attrib_crop(\n",
    "        paths[1],\n",
    "        720,\n",
    "        1450,\n",
    "        3000,\n",
    "        3210,\n",
    "        len(attrib_2_keys),\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789\",\n",
    "    )\n",
    "    attrib_2 = [int(a) for a in attrib_2]\n",
    "    attrib |= dict(zip(attrib_2_keys, attrib_2))\n",
    "\n",
    "    # Process additional attributes: Accuracy Rating ... Attack Speed\n",
    "    attrib_3_keys = [\n",
    "        \"AccuracyRating\",\n",
    "        \"EvasionRating\",\n",
    "        \"CriticalHitChance\",\n",
    "        \"CriticalResistance\",\n",
    "        \"CriticalHitDamage\",\n",
    "        \"AttackSpeed\",\n",
    "    ]\n",
    "    attrib_3 = process_attrib_crop(\n",
    "        paths[2],\n",
    "        600,\n",
    "        1490,\n",
    "        3000,\n",
    "        3210,\n",
    "        len(attrib_3_keys),\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789.\",\n",
    "    )\n",
    "    attrib_3 = [float(a) / 100 for a in attrib_3]\n",
    "    attrib |= dict(zip(attrib_3_keys, attrib_3))\n",
    "\n",
    "    # Process additional attributes: Cooldown Reduction ... Life Regeneration\n",
    "    attrib_4_keys = [\n",
    "        \"CooldownReduction\",\n",
    "        \"MovementSpeed\",\n",
    "        \"BlockChance\",\n",
    "        \"LifeDrain\",\n",
    "        \"CheatDeath\",\n",
    "        \"LifeRegeneration\",\n",
    "    ]\n",
    "    attrib_4 = process_attrib_crop(\n",
    "        paths[3],\n",
    "        690,\n",
    "        1590,\n",
    "        3000,\n",
    "        3210,\n",
    "        len(attrib_4_keys),\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789.\",\n",
    "    )\n",
    "    attrib_4 = [float(a) / 100 for a in attrib_4]\n",
    "    attrib |= dict(zip(attrib_4_keys, attrib_4))\n",
    "\n",
    "    # Process additional attributes: Damage Increase ... Resonance\n",
    "    attrib_5_keys = [\n",
    "        \"DamageIncrease\",\n",
    "        \"DefenseIncrease\",\n",
    "        \"MagicFind\",\n",
    "        \"Resonance\",\n",
    "    ]\n",
    "    attrib_5 = process_attrib_crop(\n",
    "        paths[4],\n",
    "        1060,\n",
    "        1630,\n",
    "        3000,\n",
    "        3210,\n",
    "        len(attrib_5_keys),\n",
    "        config=\"--psm 6 -c tessedit_char_whitelist=0123456789.\",\n",
    "    )\n",
    "    for i, a in enumerate(attrib_5[0:3]):\n",
    "        attrib_5[i] = float(a) / 100\n",
    "    attrib_5[3] = int(attrib_5[3])\n",
    "    attrib |= dict(zip(attrib_5_keys, attrib_5))\n",
    "\n",
    "    return attrib\n",
    "\n",
    "\n",
    "def run(path):\n",
    "    df1 = pd.DataFrame()\n",
    "\n",
    "    # Process screenshots in batches of 26: 1 screenshot for 5 rows from the member table\n",
    "    # and 5 screenshots per member for attributes. The first batch is only 21 screenshots\n",
    "    # due to the current user always being the first member and opening their profile\n",
    "    # from the member table is unsupported.\n",
    "    is_first_page = True\n",
    "\n",
    "    screenshots = sorted(path.glob(\"*.png\"))\n",
    "    screenshot_batches = chain(\n",
    "        zip(*[iter(screenshots[:21])] * 21), zip(*[iter(screenshots[21:])] * 26)\n",
    "    )\n",
    "\n",
    "    for member_table_screenshot, *member_profile_screenshots in tqdm(\n",
    "        screenshot_batches, total=300 / 5, desc=\"Member pages\"\n",
    "    ):\n",
    "        try:\n",
    "            df2 = process_members(member_table_screenshot)\n",
    "        except Exception as e:\n",
    "            print(\"Error processing file: \" + str(member_table_screenshot))\n",
    "            raise e\n",
    "\n",
    "        member_attrib = [{}] if is_first_page else []\n",
    "        for member_profile_screenshot_batch in tqdm(\n",
    "            zip(*[iter(member_profile_screenshots)] * 5),\n",
    "            total=(4 if is_first_page else 5),\n",
    "        ):\n",
    "            try:\n",
    "                member_attrib.append(\n",
    "                    process_member_attributes(member_profile_screenshot_batch)\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(\n",
    "                    \"Error processing file(s): \"\n",
    "                    + \", \".join([str(s) for s in member_profile_screenshot_batch])\n",
    "                )\n",
    "                raise e\n",
    "\n",
    "        df3 = pd.DataFrame(member_attrib)\n",
    "        df2 = df2.join(df3)\n",
    "        df1 = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "        is_first_page = False\n",
    "\n",
    "    # De-dupe to handle the case when there are less than 300 members.\n",
    "    df1 = df1.drop_duplicates(\"Name\", ignore_index=True)\n",
    "\n",
    "    return df1\n",
    "\n",
    "\n",
    "df = run(path_screenshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../out/members.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bed105675c5aa4ed30b5ebd54829dfa34d08994cc72d195e14e2440358def735"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
